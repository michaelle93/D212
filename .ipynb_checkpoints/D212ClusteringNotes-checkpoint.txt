--Unsupervised learning--
finds patterns in data

k-means clustering

from sklearn.cluster import KMeans
model= KMeans(n_clusters=3)
model.fit(samples)

labels = model.predict(samples)
print(labels)

-cluster labels for new samples-

print(new_samples)
new_labels = model.predict(new_samples)
print(new_labels)

-scatter plot- 

import matplotlib.pyplot as plt
xs = samples[:,0] (calling for variable in the 0th column)
ys = samples[:,2] (calling for variable in the 2nd column)
plt.scatter(xs, ys, c=labels)
plt.show()


from matplotlib import pyplot as plt
#assign columns of new points 
xs=new_points[:,0]
ys=new_points[:,1]
plt.scatter(xs, ys, c=labels)
#assign the cluster centers: centroids
centroids = model.cluster_centers_
#assign the columns of centroids
centroids_x = centroids[:,0]
centroids_y = centroids[:,1]
#make scatter of centroid x, y
plt.scatter(centroids_x, centroids_y, marker='D',
s=50)
plt.show()

--Evaluating a cluster--

aligning labels and species
import pandas as pd
df= pd.DataFrame({'labels': labels, 'species': species})
print(df)

ct= pd.crosstab(df['labels'], df['species'])
print(ct)
--
model = KMeans(n_clusters=3)
labels = model.fit_predict(samples)
df = pd.DataFrame({'labels': labels, 'varieties': varieties})
ct= pd.crosstab(df['labels'], df['varieties'])
print(ct)

-inertia measures clustering quality-
	measures how spread out clusters are(low better)
	distance from each sample to centroid of cluster
	after fit(), available as attribute intertia_
	cloose 'elbow' in the inertia plot'

from sklearn.cluster import KMeans
model = KMeans(n_clusters=3)
model.fit(samples)
print(model.interia_)
--
ks = range(1,6)
inertias = []
for k in ks:
	model = KMeans(n_clusters=k)
	model.fit(samples)
	inertias.append(model.inertia_)
plt.plot(ks, inertias, '-o')
plt.xlabel('number of clusters, k')
plt.ylabel('inertia')
plt.xticks(ks)
plt.show()